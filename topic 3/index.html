<!DOCTYPE html>
<html>
<head>
<title>Topic 3 Notes.md</title>
<meta http-equiv="Content-type" content="text/html;charset=UTF-8">

<style>
/* https://github.com/microsoft/vscode/blob/master/extensions/markdown-language-features/media/markdown.css */
/*---------------------------------------------------------------------------------------------
 *  Copyright (c) Microsoft Corporation. All rights reserved.
 *  Licensed under the MIT License. See License.txt in the project root for license information.
 *--------------------------------------------------------------------------------------------*/

body {
	font-family: var(--vscode-markdown-font-family, -apple-system, BlinkMacSystemFont, "Segoe WPC", "Segoe UI", "Ubuntu", "Droid Sans", sans-serif);
	font-size: var(--vscode-markdown-font-size, 14px);
	padding: 0 26px;
	line-height: var(--vscode-markdown-line-height, 22px);
	word-wrap: break-word;
}

#code-csp-warning {
	position: fixed;
	top: 0;
	right: 0;
	color: white;
	margin: 16px;
	text-align: center;
	font-size: 12px;
	font-family: sans-serif;
	background-color:#444444;
	cursor: pointer;
	padding: 6px;
	box-shadow: 1px 1px 1px rgba(0,0,0,.25);
}

#code-csp-warning:hover {
	text-decoration: none;
	background-color:#007acc;
	box-shadow: 2px 2px 2px rgba(0,0,0,.25);
}

body.scrollBeyondLastLine {
	margin-bottom: calc(100vh - 22px);
}

body.showEditorSelection .code-line {
	position: relative;
}

body.showEditorSelection .code-active-line:before,
body.showEditorSelection .code-line:hover:before {
	content: "";
	display: block;
	position: absolute;
	top: 0;
	left: -12px;
	height: 100%;
}

body.showEditorSelection li.code-active-line:before,
body.showEditorSelection li.code-line:hover:before {
	left: -30px;
}

.vscode-light.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(0, 0, 0, 0.15);
}

.vscode-light.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(0, 0, 0, 0.40);
}

.vscode-light.showEditorSelection .code-line .code-line:hover:before {
	border-left: none;
}

.vscode-dark.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(255, 255, 255, 0.4);
}

.vscode-dark.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(255, 255, 255, 0.60);
}

.vscode-dark.showEditorSelection .code-line .code-line:hover:before {
	border-left: none;
}

.vscode-high-contrast.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(255, 160, 0, 0.7);
}

.vscode-high-contrast.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(255, 160, 0, 1);
}

.vscode-high-contrast.showEditorSelection .code-line .code-line:hover:before {
	border-left: none;
}

img {
	max-width: 100%;
	max-height: 100%;
}

a {
	text-decoration: none;
}

a:hover {
	text-decoration: underline;
}

a:focus,
input:focus,
select:focus,
textarea:focus {
	outline: 1px solid -webkit-focus-ring-color;
	outline-offset: -1px;
}

hr {
	border: 0;
	height: 2px;
	border-bottom: 2px solid;
}

h1 {
	padding-bottom: 0.3em;
	line-height: 1.2;
	border-bottom-width: 1px;
	border-bottom-style: solid;
}

h1, h2, h3 {
	font-weight: normal;
}

table {
	border-collapse: collapse;
}

table > thead > tr > th {
	text-align: left;
	border-bottom: 1px solid;
}

table > thead > tr > th,
table > thead > tr > td,
table > tbody > tr > th,
table > tbody > tr > td {
	padding: 5px 10px;
}

table > tbody > tr + tr > td {
	border-top: 1px solid;
}

blockquote {
	margin: 0 7px 0 5px;
	padding: 0 16px 0 10px;
	border-left-width: 5px;
	border-left-style: solid;
}

code {
	font-family: Menlo, Monaco, Consolas, "Droid Sans Mono", "Courier New", monospace, "Droid Sans Fallback";
	font-size: 1em;
	line-height: 1.357em;
}

body.wordWrap pre {
	white-space: pre-wrap;
}

pre:not(.hljs),
pre.hljs code > div {
	padding: 16px;
	border-radius: 3px;
	overflow: auto;
}

pre code {
	color: var(--vscode-editor-foreground);
	tab-size: 4;
}

/** Theming */

.vscode-light pre {
	background-color: rgba(220, 220, 220, 0.4);
}

.vscode-dark pre {
	background-color: rgba(10, 10, 10, 0.4);
}

.vscode-high-contrast pre {
	background-color: rgb(0, 0, 0);
}

.vscode-high-contrast h1 {
	border-color: rgb(0, 0, 0);
}

.vscode-light table > thead > tr > th {
	border-color: rgba(0, 0, 0, 0.69);
}

.vscode-dark table > thead > tr > th {
	border-color: rgba(255, 255, 255, 0.69);
}

.vscode-light h1,
.vscode-light hr,
.vscode-light table > tbody > tr + tr > td {
	border-color: rgba(0, 0, 0, 0.18);
}

.vscode-dark h1,
.vscode-dark hr,
.vscode-dark table > tbody > tr + tr > td {
	border-color: rgba(255, 255, 255, 0.18);
}

</style>

<style>
/* Tomorrow Theme */
/* http://jmblog.github.com/color-themes-for-google-code-highlightjs */
/* Original theme - https://github.com/chriskempson/tomorrow-theme */

/* Tomorrow Comment */
.hljs-comment,
.hljs-quote {
	color: #8e908c;
}

/* Tomorrow Red */
.hljs-variable,
.hljs-template-variable,
.hljs-tag,
.hljs-name,
.hljs-selector-id,
.hljs-selector-class,
.hljs-regexp,
.hljs-deletion {
	color: #c82829;
}

/* Tomorrow Orange */
.hljs-number,
.hljs-built_in,
.hljs-builtin-name,
.hljs-literal,
.hljs-type,
.hljs-params,
.hljs-meta,
.hljs-link {
	color: #f5871f;
}

/* Tomorrow Yellow */
.hljs-attribute {
	color: #eab700;
}

/* Tomorrow Green */
.hljs-string,
.hljs-symbol,
.hljs-bullet,
.hljs-addition {
	color: #718c00;
}

/* Tomorrow Blue */
.hljs-title,
.hljs-section {
	color: #4271ae;
}

/* Tomorrow Purple */
.hljs-keyword,
.hljs-selector-tag {
	color: #8959a8;
}

.hljs {
	display: block;
	overflow-x: auto;
	color: #4d4d4c;
	padding: 0.5em;
}

.hljs-emphasis {
	font-style: italic;
}

.hljs-strong {
	font-weight: bold;
}
</style>

<style>
/*
 * Markdown PDF CSS
 */

 body {
	font-family: -apple-system, BlinkMacSystemFont, "Segoe WPC", "Segoe UI", "Ubuntu", "Droid Sans", sans-serif, "Meiryo";
	padding: 0 12px;
}

pre {
	background-color: #f8f8f8;
	border: 1px solid #cccccc;
	border-radius: 3px;
	overflow-x: auto;
	white-space: pre-wrap;
	overflow-wrap: break-word;
}

pre:not(.hljs) {
	padding: 23px;
	line-height: 19px;
}

blockquote {
	background: rgba(127, 127, 127, 0.1);
	border-color: rgba(0, 122, 204, 0.5);
}

.emoji {
	height: 1.4em;
}

code {
	font-size: 14px;
	line-height: 19px;
}

/* for inline code */
:not(pre):not(.hljs) > code {
	color: #C9AE75; /* Change the old color so it seems less like an error */
	font-size: inherit;
}

/* Page Break : use <div class="page"/> to insert page break
-------------------------------------------------------- */
.page {
	page-break-after: always;
}

</style>

<script src="https://unpkg.com/mermaid/dist/mermaid.min.js"></script>
</head>
<body>
  <script>
    mermaid.initialize({
      startOnLoad: true,
      theme: document.body.classList.contains('vscode-dark') || document.body.classList.contains('vscode-high-contrast')
          ? 'dark'
          : 'default'
    });
  </script>
<h1 id="topic-3---linear-regression">TOPIC 3 - LINEAR REGRESSION</h1>
<h3 id="initialise-working-directory-and-read-file">Initialise working directory and read file</h3>
<pre class="hljs"><code><div>setwd(<span class="hljs-string">"/Users/yizhong/School/Y2S1/DSA1101/Data"</span>)
resale = read.csv(<span class="hljs-string">"hdbresale_reg.csv"</span>)
</div></code></pre>
<h3 id="view-sample-data">View sample data</h3>
<pre class="hljs"><code><div>head(resale[ ,<span class="hljs-number">2</span>:<span class="hljs-number">7</span>]) <span class="hljs-comment"># 1st column indicates ID of flats</span>
</div></code></pre>
<table>
<thead>
<tr>
<th>month</th>
<th>town</th>
<th>flat_type</th>
<th>block</th>
<th>street_name</th>
<th>storey_range</th>
</tr>
</thead>
<tbody>
<tr>
<td>2012-03</td>
<td>CENTRAL AREA</td>
<td>3 ROOM</td>
<td>640</td>
<td>ROWELL RD</td>
<td>01 TO 05</td>
</tr>
<tr>
<td>2012-03</td>
<td>CENTRAL AREA</td>
<td>3 ROOM</td>
<td>640</td>
<td>ROWELL RD</td>
<td>06 TO 10</td>
</tr>
<tr>
<td>2012-03</td>
<td>CENTRAL AREA</td>
<td>3 ROOM</td>
<td>668</td>
<td>CHANDER RD</td>
<td>01 TO 05</td>
</tr>
<tr>
<td>2012-03</td>
<td>CENTRAL AREA</td>
<td>3 ROOM</td>
<td>5</td>
<td>TG PAGAR PLAZA</td>
<td>11 TO 15</td>
</tr>
<tr>
<td>2012-03</td>
<td>CENTRAL AREA</td>
<td>3 ROOM</td>
<td>271</td>
<td>QUEEN ST</td>
<td>11 TO 15</td>
</tr>
<tr>
<td>2012-03</td>
<td>CENTRAL AREA</td>
<td>4 ROOM</td>
<td>671A</td>
<td>KLANG LANE</td>
<td>01 TO 05</td>
</tr>
</tbody>
</table>
<pre class="hljs"><code><div>head(resale[ ,<span class="hljs-number">8</span>:<span class="hljs-number">11</span>])
</div></code></pre>
<table>
<thead>
<tr>
<th>floor_area_sqm</th>
<th>flat_model</th>
<th>lease_commence_date</th>
<th>resale_price</th>
</tr>
</thead>
<tbody>
<tr>
<td>74</td>
<td>Model A</td>
<td>1984</td>
<td>380000</td>
</tr>
<tr>
<td>74</td>
<td>Model A</td>
<td>1984</td>
<td>388000</td>
</tr>
<tr>
<td>73</td>
<td>Model A</td>
<td>1984</td>
<td>400000</td>
</tr>
<tr>
<td>59</td>
<td>Improved</td>
<td>1977</td>
<td>460000</td>
</tr>
<tr>
<td>68</td>
<td>Improved</td>
<td>1979</td>
<td>488000</td>
</tr>
<tr>
<td>75</td>
<td>Model A</td>
<td>2003</td>
<td>495000</td>
</tr>
</tbody>
</table>
<h3 id="simple-linear-regression-slr">Simple Linear Regression (SLR)</h3>
<p>Suppose we have three observations. Each observation has an outcome ( y ) and an input variable ( x ). We are interested in the linear relationship:</p>
<p>[
y_i \approx \beta_0 + \beta_1 x_i
]</p>
<p>Since there is only <strong>one</strong> input variable, this is an example of a <strong>simple linear model</strong>.</p>
<h3 id="modelling">Modelling</h3>
<pre class="hljs"><code><div>x = c( -<span class="hljs-number">1</span>, <span class="hljs-number">3</span>, <span class="hljs-number">5</span>)
y = c( -<span class="hljs-number">1</span>, <span class="hljs-number">3.5</span> , <span class="hljs-number">3</span>)
lm(y~x)
</div></code></pre>
<pre class="hljs"><code><div>Coefficients:
(Intercept)            x
     0.1250       0.7321
</div></code></pre>
<p>We can now write the <strong>fitted model</strong> as: [\hat{y} = 0.125 + 0.7321x]</p>
<h3 id="predicting">Predicting</h3>
<p>With the fitted model, we can now obtain the fitted outcome (predicted outcome) value ( \hat{y} ) given any value of the predictor, ( x ).</p>
<p>For example, if ( x = 2), then the fitted value for the outcome is:</p>
<p>[\hat{y} = 0.125 + 0.7321 \times 2 = 1.589]</p>
<pre class="hljs"><code><div>M = lm(y~x) <span class="hljs-comment"># M = name of the fitted model</span>
new = data.frame(x = <span class="hljs-number">2</span>) <span class="hljs-comment"># create dataframe of new point</span>
predict(M, newdata = new)
</div></code></pre>
<pre class="hljs"><code><div>       1
1.589286
</div></code></pre>
<h3 id="model-for-hdb-resale-flats">Model for HDB Resale Flats</h3>
<pre class="hljs"><code><div>price = resale$resale_price
area = resale$floor_area_sqm
hdb.model = lm(price~area)
hdb.model$coef <span class="hljs-comment"># coefficients of the hdb model</span>
</div></code></pre>
<pre class="hljs"><code><div>(Intercept)        area
 115145.730    3117.212
</div></code></pre>
<p>The fitted model is then</p>
<p>[\hat{y} = 115145.730 + 3117.212 \times area]</p>
<p>where y is the resale price of a flat, in SGD.</p>
<h3 id="goodness-of-fit-of-model">Goodness-of-fit of Model</h3>
<p>The goodness-of-fit of a model could be accessed by some measures. In this course, we consider only two basic measurements:</p>
<ul>
<li>The significance of the model by a test (F-test).</li>
<li>Coefficient of determination, (R^2).</li>
</ul>
<p>When comparing the goodness-of-fit of two models with the <strong>same response</strong>, we can use Residual Standard Error (RSE) as a criterion.</p>
<h3 id="f-test">F-test</h3>
<p>To test if the whole model is significant or not, we use F-test.</p>
<p>Its null hypothesis (( H_0 )) states &quot;model is NOT significant&quot;. Its alternative (( H_1 )) states &quot;model is significant&quot;. Equivalently:</p>
<ul>
<li>( H_0 ) : all the coefficients, except intercept, are zero.</li>
<li>( H_1 ): at least one of the coefficients (except intercept), is NON-zero.</li>
</ul>
<p>If the test has a small p-value (such as ( &lt; 0.05 )), then data provide strong evidence against ( H_0 ). Otherwise, we cannot eliminate ( H_0 ).</p>
<pre class="hljs"><code><div>summary(hdb.model)
</div></code></pre>
<pre class="hljs"><code><div>Call:
lm(formula = price ~ area)

Residuals:
    Min      1Q  Median      3Q     Max
-122852  -33539  -10984   17298  488719

Coefficients:
             Estimate Std. Error t value Pr(&gt;|t|)
(Intercept) 115145.73    2949.14   39.04   &lt;2e-16 ***
area          3117.21      27.95  111.54   &lt;2e-16 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 56410 on 6053 degrees of freedom
Multiple R-squared:  0.6727,	Adjusted R-squared:  0.6727
F-statistic: 1.244e+04 on 1 and 6053 DF,  p-value: &lt; 2.2e-16
</div></code></pre>
<p>Notice the last line's extremely low p-value. That serves as strong evidence against ( H_0 ).</p>
<h3 id="coefficient-of-determination--r2">Coefficient of Determination ( R^2 )</h3>
<p><strong>Total sum of squares (( TSS ))</strong> measures the total variance in the response in the given data, and can be thought of as the amount of variability inherent in the response before the regression is performed.</p>
<p>[
TSS = \sum_{i=1}^{n} (y_i - \bar{y})^2
]</p>
<p><strong>Residual sum of squares (( RSS ))</strong> measures the amount of variability that is left unexplained after performing the regression.</p>
<p>[
RSS = \sum_{i=1}^{n} (y_i - \hat{y_i})^2
]</p>
<p>The quantity <strong>( R^2 )</strong> (coefficient of determination) is defined as:</p>
<p>[
R^2 = \frac{TSS - RSS}{TSS} = 1 - \frac{RSS}{TSS}
]</p>
<p>( R^2 ) measures the proportion of variability in the response Y that is explained by the fitted model. Larger( R^2 ) indicates better model fit.</p>
<p><strong>Derieving ( R^2 ) directly:</strong></p>
<pre class="hljs"><code><div>TSS = var(y)\*(length(y) -<span class="hljs-number">1</span>) <span class="hljs-comment"># or</span>
TSS = sum((y- mean (y)) ^<span class="hljs-number">2</span>)

RSS =sum((y- M$fitted )^<span class="hljs-number">2</span>)

R2 = <span class="hljs-number">1</span> - RSS/TSS; R2
</div></code></pre>
<pre class="hljs"><code><div>[1] 0.822407
</div></code></pre>
<p><strong>Getting ( R^2 ) from model output:</strong></p>
<pre class="hljs"><code><div>summary(M)$r.squared
</div></code></pre>
<pre class="hljs"><code><div>[1] 0.822407
</div></code></pre>
<h3 id="residual-standard-error-rse">Residual Standard Error (RSE):</h3>
<p>RSE in <strong>simple</strong> linear regression is defined as:</p>
<p>[
RSE = \sqrt{\frac{RSS}{n - p - 1}}
]</p>
<p>For the same response, one may fit many different linear models, and the one with large RSE indicates poorer model fit.</p>
<pre class="hljs"><code><div>summary(M)$sigma
</div></code></pre>
<pre class="hljs"><code><div>[1] 1.469937
</div></code></pre>
<h3 id="multiple-linear-regression-mlr">Multiple Linear Regression (MLR)</h3>
<p>Suppose we have ( n ) observations. Each observation has an outcome ( y ) and multiple input variables ( x^1, \ldots, x^p ).</p>
<p>We are interested in the linear relationship:</p>
<p>[
y \approx \beta_0 + \beta_1 x^1 + \beta_2 x^2 + \dots + \beta_p x^p
]</p>
<p>or equivalently:</p>
<p>[
y_i \approx \beta_0 + \beta_1 x_i^1 + \beta_2 x_i^2 + \dots + \beta_p x_i^p, \quad i = 1, \dots, n.
]</p>
<p>The least squares estimates of (\beta_0, \beta_1, \beta_2, \dots, \beta_p ) are returned by the <code>lm()</code> function in R.</p>
<p>Consider a simulated data with (x^1,x^2) and response (y) where (y) is created as ((1 + 2x^1 − 5x^2)) with some noise added.</p>
<pre class="hljs"><code><div>set.seed(<span class="hljs-number">520</span>)
x1 = rnorm(<span class="hljs-number">100</span>)
x2 = rnorm(<span class="hljs-number">100</span>)
y = <span class="hljs-number">1</span> + <span class="hljs-number">2</span>*x1 -<span class="hljs-number">5</span>*x2+ rnorm(<span class="hljs-number">100</span>)
</div></code></pre>
<p>A fitted linear model, (y \sim x^1 + x^2), can be obtained as such:</p>
<pre class="hljs"><code><div>lm(y~x1+x2)
</div></code></pre>
<pre class="hljs"><code><div>Coefficients:
(Intercept)           x1           x2
      1.062        2.048       -5.197
</div></code></pre>
<h3 id="adjusted-r2-in-mlr">Adjusted (R^2) in MLR</h3>
<p>( R^2 ) can be inflated simply by adding more regressors to the model (even insignificant terms).</p>
<p>We have adjusted ( R^2 ), denoted as ( R^2_{adj} ), which penalizes the model for adding regressors of too little help to the model.</p>
<p>[
R^2_{adj} = 1 - \frac{RSS / (n - p - 1)}{TSS / (n - 1)}
]</p>
<p>When comparing two models of the same response, the model with the larger ( R^2_{adj} ) is preferred.</p>
<pre class="hljs"><code><div>summary(some_model)$adj.r.squared
</div></code></pre>
<h3 id="dividing-full-dataset-into-train-set-and-test-set-randomly">Dividing Full Dataset into Train Set and Test Set Randomly</h3>
<ol>
<li>Mix up all the indices of the full data:</li>
</ol>
<pre class="hljs"><code><div>n = dim(resale)[<span class="hljs-number">1</span>] <span class="hljs-comment"># total number of rows/observations</span>

index.train = sample(<span class="hljs-number">1</span>:n)[<span class="hljs-number">1</span>:(<span class="hljs-number">0.8</span>*n)]
</div></code></pre>
<ul>
<li>This 2nd line generates a random sample of indices from the range <code>1:n</code> (where n is the total number of observations).</li>
<li><code>1:n</code> generates a sequence from 1 to n.</li>
<li><code>0.8*n</code> specifies that you want to sample 80% of the total number of observations (which is often used to create a training dataset).</li>
</ul>
<ol start="2">
<li>Take the first 80% of those mixed indices as indices of train data and the remaining 20% as indices of test data:</li>
</ol>
<pre class="hljs"><code><div>train.data = resale[index.train, ]
test.data = resale[ - index.train, ]
</div></code></pre>
<ol start="3">
<li>Form the model based on the train set:</li>
</ol>
<pre class="hljs"><code><div>M3 = lm(resale_price ~ floor_area_sqm, data = train.data)
summary(M3)
</div></code></pre>
<ol start="4">
<li>Predict the response for test set:</li>
</ol>
<pre class="hljs"><code><div>prediction = predict(M3, test.data); prediction
</div></code></pre>
<ol start="5">
<li>View prediction (first column prediction while second column is the actual price):</li>
</ol>
<pre class="hljs"><code><div>cbind(prediction, test.data$resale_price)
</div></code></pre>
<h3 id="adding-categorical-variables-to-the-mlr-model">Adding Categorical Variables to the MLR Model</h3>
<p><strong>FOR THIS TO WORK, CONVERT VARIABLE TO CATEGORICAL IF IT IS NOT!</strong></p>
<pre class="hljs"><code><div>M4 = lm(resale_price ~ floor_area_sqm + flat_type, data = resale)
summary(M4)
</div></code></pre>
<pre class="hljs"><code><div>Residuals:
    Min      1Q  Median      3Q     Max
-113637  -31066   -9668   15379  492762

Coefficients:
                   Estimate Std. Error t value Pr(&gt;|t|)
(Intercept)        183375.6     8754.4  20.947  &lt; 2e-16 ***
floor_area_sqm       1904.9       84.1  22.650  &lt; 2e-16 ***
flat_type3 ROOM     24712.7     7934.2   3.115  0.00185 **
flat_type4 ROOM     42897.9     8651.9   4.958 7.31e-07 ***
flat_type5 ROOM     66198.2     9716.1   6.813 1.05e-11 ***
flat_typeEXECUTIVE 156561.4    11698.3  13.383  &lt; 2e-16 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 53500 on 6049 degrees of freedom
Multiple R-squared:  0.7058,	Adjusted R-squared:  0.7056
F-statistic:  2903 on 5 and 6049 DF,  p-value: &lt; 2.2e-16
</div></code></pre>
<p>FLAT TYPE has 5 categories. R chooses <code>2 ROOM</code> as reference category, and this can be inferred from the fact that its coefficient is not given.</p>
<p>Coefficient 26753.48 of <code>3 ROOM</code> means:</p>
<ul>
<li>fixing other variables in the model, compared to a <code>2 ROOM</code> flat then on average, a <code>3 ROOM</code> flat is more expensive by $26753.48.</li>
</ul>
<h3 id="assumptions-of-response-to-form-a-linear-model">Assumptions of Response to Form a Linear Model</h3>
<ol>
<li>Response should be <strong>symmetric</strong>.</li>
<li><strong>Variability of response is stable when regressors change.</strong></li>
</ol>
<h3 id="checking-for-response-symmetry-1">Checking for response symmetry (1)</h3>
<p>At our level, checking the symmetry by histogram would be enough.</p>
<pre class="hljs"><code><div>hist(resale$resale_price) <span class="hljs-comment"># if we plan to use full data to form model</span>
hist(train.data$resale_price) <span class="hljs-comment"># if we plan to use train.data to form the model</span>
</div></code></pre>
<div style="text-align: center;">
  <img src="diagrams/traindataresalepricehistogram.png" alt="Right skewed response histogram" style="max-height: 400px;">
</div>
<p>In both cases, the response is <strong>NOT symmetric</strong>, and is very <strong>right skewed</strong>. Hence, it's <strong>NOT SUITABLE</strong> to fit a linear model for resale price.</p>
<h4 id="solution-for-asymmetric-response-transformation">Solution for asymmetric response: Transformation</h4>
<p>After transformation, such as taking log-e, or sqrt, the response is more symmetric.</p>
<pre class="hljs"><code><div>hist(log(resale$resale_price)) <span class="hljs-comment"># slightly better, more symmetric</span>
</div></code></pre>
<div style="text-align: center;">
  <img src="diagrams/logtraindataresalepricehistogram.png" alt="More symmetric response histogram" style="max-height: 400px;">
</div>
<p>Hence, fitting a linear model for the log-e of the price is better than fitting a LM for the price itself.</p>
<h3 id="checking-for-stability-of-variability-of-response-2">Checking for Stability of Variability of Response (2)</h3>
<p>Use scatter plot of ( y ) vs quantitative ( x ), and check if the range of response is stable when ( x ) changes.</p>
<pre class="hljs"><code><div>plot(resale$floor_area_sqm, resale$resale_price)
</div></code></pre>
<div style="text-align: center;">
  <img src="diagrams/floorareasqmagainstresaleprice.png"
  style="max-height: 400px;">
</div>
<hr>
<pre class="hljs"><code><div>plot(resale$age, resale$resale_price)
</div></code></pre>
<div style="text-align: center;">
  <img src="diagrams/leasecommencedateagainstresaleprice.png"  style="max-height: 400px;">
</div>

</body>
</html>
